// File: /packages/backend/src/services/embedding.service.js

const { geminiClient: ai } = require('./llm.provider');
const { handleGeminiError, createGeminiErrorLog } = require('../utils/geminiErrorHandler');

// –û—Ç–∫–ª—é—á–∞–µ–º –º–æ–∫–∏ - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ —Ä–µ–∞–ª—å–Ω—ã–π API
const USE_MOCK_EMBEDDINGS = false;

/**
 * Generate embedding vector for text using Google's gemini-embedding-001 model
 * @param {string} text - Text to generate embedding for
 * @param {Object} options - Additional options
 * @returns {Promise<number[]>} - Array of 768 float values representing the embedding
 */
async function generateEmbedding(text, options = {}) {
  
  try {
    console.log(`üîç –ì–µ–Ω–µ—Ä–∏—Ä—É—é embedding –¥–ª—è: "${text.substring(0, 50)}${text.length > 50 ? '...' : ''}"`);
    
    const response = await ai.models.embedContent({
      model: options.model || process.env.GEMINI_EMBEDDING_MODEL || 'gemini-embedding-001',
      contents: [text],
      config: {
        taskType: options.taskType || "RETRIEVAL_DOCUMENT",
        outputDimensionality: options.outputDimensionality || 768
      }
    });
    
    // –ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ values –∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –æ—Ç–≤–µ—Ç–∞
    if (!response.embeddings || response.embeddings.length === 0) {
      throw new Error('API returned no embeddings.');
    }
    
    const embeddingObject = response.embeddings[0];
    const embedding = embeddingObject.values;
    const stats = embeddingObject.statistics;
    
    // The `statistics` object is optional
    if (stats && typeof stats.token_count !== 'undefined') {
      console.log(`‚úÖ Embedding —Å–æ–∑–¥–∞–Ω: ${embedding.length} –∏–∑–º–µ—Ä–µ–Ω–∏–π, ${stats.token_count} —Ç–æ–∫–µ–Ω–æ–≤`);
      if (stats.truncated) {
        console.warn('‚ö†Ô∏è  –¢–µ–∫—Å—Ç –±—ã–ª –æ–±—Ä–µ–∑–∞–Ω –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ embedding');
      }
    } else {
      console.log(`‚úÖ Embedding —Å–æ–∑–¥–∞–Ω: ${embedding.length} –∏–∑–º–µ—Ä–µ–Ω–∏–π (—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞)`);
    }
    
    return embedding;
    
  } catch (error) {
    // –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫ Gemini API
    const geminiErrorInfo = handleGeminiError(error, { 
      language: 'ru', 
      includeRetryInfo: true 
    });
    
    // –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ª–æ–≥
    const errorLog = createGeminiErrorLog(error, {
      operation: 'embedding_generation',
      text: text.substring(0, 50), // –ü–µ—Ä–≤—ã–µ 50 —Å–∏–º–≤–æ–ª–æ–≤ —Ç–µ–∫—Å—Ç–∞
      isTemporary: geminiErrorInfo.isTemporary
    });
    
    // –í—ã–≤–æ–¥–∏–º –ª–æ–≥ –≤ –∫–æ–Ω—Å–æ–ª—å —Å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–º —É—Ä–æ–≤–Ω–µ–º
    if (errorLog.level === 'warn') {
      console.warn('üö¶ GEMINI EMBEDDING LIMIT:', errorLog.userMessage);
      console.warn('   Retry in:', errorLog.retryDelay + 's');
    } else {
      console.error('‚ùå GEMINI EMBEDDING ERROR:', errorLog.userMessage);
      console.error('   This will cause item import to FAIL!');
    }
    
    throw error;
  }
}

/**
 * Generate embeddings for multiple texts at once
 * @param {string[]} texts - Array of texts to generate embeddings for
 * @param {Object} options - Additional options
 * @returns {Promise<number[][]>} - Array of embedding vectors
 */
async function generateBatchEmbeddings(texts, options = {}) {
  
  try {
    console.log(`üîç –ì–µ–Ω–µ—Ä–∏—Ä—É—é batch embeddings –¥–ª—è ${texts.length} —Ç–µ–∫—Å—Ç–æ–≤`);
    
    const response = await ai.models.embedContent({
      model: options.model || process.env.GEMINI_EMBEDDING_MODEL || 'gemini-embedding-001',
      contents: texts,
      config: {
        taskType: options.taskType || "RETRIEVAL_DOCUMENT",
        outputDimensionality: options.outputDimensionality || 768
      }
    });
    
    // –ò–∑–≤–ª–µ–∫–∞–µ–º values –∏–∑ –∫–∞–∂–¥–æ–≥–æ embedding
    const embeddings = response.embeddings.map(embedding => embedding.values);
    const totalTokens = response.embeddings.reduce((sum, emb) => {
      return sum + (emb.statistics?.token_count || 0);
    }, 0);
    
    console.log(`‚úÖ Batch embeddings —Å–æ–∑–¥–∞–Ω—ã: ${embeddings.length} –≤–µ–∫—Ç–æ—Ä–æ–≤, ${totalTokens} —Ç–æ–∫–µ–Ω–æ–≤`);
    
    return embeddings;
    
  } catch (error) {
    const geminiErrorInfo = handleGeminiError(error, { 
      language: 'ru', 
      includeRetryInfo: true 
    });
    
    console.error('‚ùå GEMINI BATCH EMBEDDING ERROR:', geminiErrorInfo.userMessage);
    throw error;
  }
}

/**
 * Get embedding statistics for text
 * @param {string} text - Text to analyze
 * @param {Object} options - Additional options
 * @returns {Promise<Object>} - Statistics object
 */
async function getEmbeddingStats(text, options = {}) {
  
  try {
    const response = await ai.models.embedContent({
      model: options.model || process.env.GEMINI_EMBEDDING_MODEL || 'gemini-embedding-001',
      contents: [text],
      config: {
        taskType: options.taskType || "RETRIEVAL_DOCUMENT",
        outputDimensionality: options.outputDimensionality || 768
      }
    });
    
    const embedding = response.embeddings[0];
    
    return {
      dimensions: embedding.values.length,
      tokenCount: embedding.statistics?.token_count ?? 0,
      truncated: embedding.statistics?.truncated ?? false,
      billableCharacters: response.metadata?.billable_character_count || 0
    };
    
  } catch (error) {
    console.error('‚ùå Error getting embedding stats:', error.message);
    throw error;
  }
}

/**
 * Convert embedding array to Float32Array buffer for sqlite-vec
 * @param {number[]} embedding - Array of float values
 * @returns {Buffer} - Buffer suitable for sqlite-vec
 */
function embeddingToBuffer(embedding) {
  const float32Array = new Float32Array(embedding);
  return Buffer.from(float32Array.buffer);
}

/**
 * Convert Buffer back to regular array
 * @param {Buffer} buffer - Buffer from sqlite-vec
 * @returns {number[]} - Array of float values
 */
function bufferToEmbedding(buffer) {
  const float32Array = new Float32Array(buffer.buffer, buffer.byteOffset, buffer.length / 4);
  return Array.from(float32Array);
}

/**
 * Convert embedding array to JSON string (deprecated - for compatibility)
 * @param {number[]} embedding - Array of float values
 * @returns {string} - JSON string
 */
function embeddingToJson(embedding) {
  return JSON.stringify(embedding);
}

/**
 * Convert string back to regular array - handles both JSON array and PostgreSQL array formats
 * @param {string} stringData - JSON array string or PostgreSQL array string
 * @returns {number[]} - Array of float values
 */
function jsonToEmbedding(stringData) {
  // Handle PostgreSQL array format like {"0.1","0.2","0.3"}
  if (stringData.startsWith('{') && stringData.endsWith('}') && !stringData.startsWith('[')) {
    const vectorStr = stringData.replace(/^\{|\}$/g, ''); // Remove curly braces
    return vectorStr.split(',').map(v => parseFloat(v.replace(/"/g, ''))); // Split and parse floats
  }
  // Handle JSON array format like [0.1,0.2,0.3]
  return JSON.parse(stringData);
}

module.exports = {
  generateEmbedding,
  generateBatchEmbeddings,
  getEmbeddingStats,
  embeddingToBuffer,
  bufferToEmbedding,
  embeddingToJson,
  jsonToEmbedding
};